## Small-File Access in Parallel File Systems

摘要：现今的计算机科学需求创造了比以往更大的并行计算机，并且，存储系统也在发展，以满足这些需求。在这种场景下使用的并行文件系统正在被特殊化来获得对于大I/O操作的更高性能，当然，这是以牺牲其它可能的负载的情况下。虽然一些应用程序已经适应了I/O的最佳实践，在这些系统中可以获得很好的性能，许多应用程序最常见的I/O模式会产生许多小文件。当规模非常大时，当前的并行文件系统不能很好地为这些应用程序提供服务。

本文描述了超大规模系统中优化并行文件系统的小文件访问的五种技术。这五种技术都实现于一个并行文件系统(PVFS)，然后在两种平台上进行系统的测试。使用一个微基准测试和mdtest基准测试来测试一个无法预料的规模的优化。结果表明，在使用16384个核心的领先的计算平台上，与PVFS的基本配置相比，在小文件创建速率上提高905%，在小文件stat速率上提升1106%，

# 1 介绍

现今的计算机科学需求创造了比以往更大的并行计算机，并且，存储系统也在发展，以满足应用程序产生数据的速率。在这种场景下使用的并行文件系统正在被专用化，试图在计算科学应用负载方面通过底层存储硬件获得可能的最佳性能。这些专用的系统很大，常常进行排列以并发访问，并且一些应用已经发现，对几个GB的大文件访问，进行大量数据的访问是提升并行文件系统性能的最佳方式。其它一些应用继续使用其它的I/O策略，获得了不同方面的成功。与此同时，在一些新的领域的科学家开始使用高性能计算(HPC)资源来攻克他们专业领域的难题，这些新的应用提出了新的I/O需求。

通过对最近的工作负载的研究，可以得到一些结论。事实上，许多HPC存储系统不仅被用来存储大文件，还用来存储许多小文件。比如，2007年，国家能源研究科学计算中心对一个共享的并行文件系统的研究表明，该并行文件系统存储了1300万个文件，99%的文件大小小于64MB，43%的文件大小小于64KB。类似的，2007年，西北太平洋国家实验室的一项研究表明，在他们的系统中有1200万个文件，94%的文件大小小于64MB，58%的文件大小小于64KB。

更多的研究表明，这些文件可以来自许多地方，而不是一个行为异常的应用。几个科学领域，比如气候学、天文学和生物学，它们都会产生方便存储的数据集，并且在文件系统上作为独立文件进行组织。下面是每个领域产生的数据集的例子：

* 45万个社区气候系统模型文件，平均大小为61MB。
* 斯隆数字巡天计划产生了2000万张图片，平均大小小于1MB。
* 人类基因组产生了大约3000万个文件，平均大小为190KB。

在并行文件系统访问大量的小文件会将I/O的挑战从提供高I/O聚合带宽转向支持高并发的元数据访问速率。现在最常用的提升文件系统元数据速率的技术是客户端缓存。然而，在HPC系统中，有大量的多核处理器，结果，每个核心只有少量的RAM。这些系统的应用通常使用内存的大多数，只有很少的空间作缓存。此外，传统的保持一致性和故障恢复的技术并不是为这种大规模而设计的。

本文中，我们探究一种隐藏延迟、减少I/O和消息传送的策略，而且它不使用客户端的额外资源。我们陈述了五种并行文件系统中提升元数据并发访问和小文件I/O性能：server-driven file precreaton, the readdirplus POSIX extension, file stuffing, metadata commit coalescing, and eager data movement for reads and writes。在这五种技术中，前两种已经在并行文件系统实现中阐述过了。剩下的三种是众所周知的优化方式，但是，我们以一种新的方式将它们应用于并行文件系统环境。本文中，所有的五种技术都在一个文件系统(PVFS)中实现，然后在一致的环境中测试它们的相对值。我们还将分析用来评价IBM Blue Gene/P系统的前所未有的规模的行为。

本文按照下面的方式来组织。第二部分，我们陈述了PVFS的相关因素。第三部分，我们讨论我们的工作中用到的每个优化小文件I/O访问的技术。第四部分，我们在两种测试环境中使用微基准测试和人工负载在测试这些技术。第五部分，我们对相关工作进行总结。第六部分，我们对我们的发现进行总结，然后提供未来的一些工作的建议。











